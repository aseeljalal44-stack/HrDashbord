"""
ÙˆØ­Ø¯Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª - ØªØ¹Ù…Ù„ Ù…Ø¹ Ø£ÙŠ Ù‡ÙŠÙƒÙ„ Ø¨ÙŠØ§Ù†Ø§Øª
Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ù…Ø¹ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
"""

import pandas as pd
import numpy as np
from datetime import datetime

class FlexibleDataAnalyzer:
    def __init__(self, dataframe, column_mapping):
        self.df = dataframe.copy()
        self.mapping = column_mapping
        self.reverse_mapping = {v: k for k, v in column_mapping.items() if v != "âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯"}
    
    def analyze_all(self):
        """Ø¥Ø¬Ø±Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©"""
        analysis_results = {
            'kpis': {},
            'distributions': {},
            'correlations': {},
            'insights': [],
            'warnings': []
        }
        
        # 1. ØªØ­Ù„ÙŠÙ„ KPIs
        analysis_results['kpis'] = self._calculate_kpis()
        
        # 2. ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        analysis_results['distributions'] = self._analyze_distributions()
        
        # 3. Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª
        analysis_results['correlations'] = self._find_correlations()
        
        # 4. Ø§Ø³ØªØ®Ù„Ø§Øµ Insights
        analysis_results['insights'] = self._extract_insights()
        
        # 5. Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª
        analysis_results['warnings'] = self._check_data_quality()
        
        return analysis_results
    
    def _calculate_kpis(self):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©"""
        kpis = {}
        
        # Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ† (Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ù…ÙˆØ¬ÙˆØ¯)
        total_employees = len(self.df)
        kpis['total_employees'] = {
            'value': f"{total_employees:,}",
            'label': 'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†',
            'icon': 'ğŸ‘¥'
        }
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø±ÙˆØ§ØªØ¨
        if 'salary' in self.mapping:
            salary_col = self.mapping['salary']
            if salary_col in self.df.columns:
                try:
                    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø¹Ø¯Ø¯ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
                    if not pd.api.types.is_numeric_dtype(self.df[salary_col]):
                        self.df[salary_col] = pd.to_numeric(self.df[salary_col], errors='coerce')
                    
                    salary_data = self.df[salary_col].dropna()
                    if len(salary_data) > 0:
                        avg_salary = salary_data.mean()
                        median_salary = salary_data.median()
                        
                        kpis['avg_salary'] = {
                            'value': f"${avg_salary:,.0f}" if not np.isnan(avg_salary) else "N/A",
                            'label': 'Ù…ØªÙˆØ³Ø· Ø§Ù„Ø±Ø§ØªØ¨',
                            'icon': 'ğŸ’°'
                        }
                        
                        kpis['median_salary'] = {
                            'value': f"${median_salary:,.0f}" if not np.isnan(median_salary) else "N/A",
                            'label': 'Ø§Ù„Ø±Ø§ØªØ¨ Ø§Ù„ÙˆØ³ÙŠØ·',
                            'icon': 'ğŸ“Š'
                        }
                except Exception as e:
                    kpis['salary_error'] = {
                        'value': 'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ø³Ø§Ø¨',
                        'label': 'Ù…ØªÙˆØ³Ø· Ø§Ù„Ø±Ø§ØªØ¨',
                        'icon': 'âš ï¸'
                    }
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø£Ù‚Ø³Ø§Ù…
        if 'department' in self.mapping:
            dept_col = self.mapping['department']
            if dept_col in self.df.columns:
                dept_count = self.df[dept_col].nunique()
                kpis['departments'] = {
                    'value': dept_count,
                    'label': 'Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…',
                    'icon': 'ğŸ¢'
                }
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø£Ø¯Ø§Ø¡
        if 'performance_score' in self.mapping:
            perf_col = self.mapping['performance_score']
            if perf_col in self.df.columns:
                try:
                    if not pd.api.types.is_numeric_dtype(self.df[perf_col]):
                        self.df[perf_col] = pd.to_numeric(self.df[perf_col], errors='coerce')
                    
                    perf_data = self.df[perf_col].dropna()
                    if len(perf_data) > 0:
                        avg_perf = perf_data.mean()
                        kpis['avg_performance'] = {
                            'value': f"{avg_perf:.1f}/5" if not np.isnan(avg_perf) else "N/A",
                            'label': 'Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø¯Ø§Ø¡',
                            'icon': 'ğŸ“ˆ'
                        }
                except:
                    pass
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ ØªÙˆØ§Ø±ÙŠØ® ØªØ¹ÙŠÙŠÙ†
        if 'hire_date' in self.mapping:
            date_col = self.mapping['hire_date']
            if date_col in self.df.columns:
                try:
                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹Ù…Ø± Ø§Ù„ØªÙ†Ø¸ÙŠÙ…ÙŠ
                    if not pd.api.types.is_datetime64_any_dtype(self.df[date_col]):
                        self.df[date_col] = pd.to_datetime(self.df[date_col], errors='coerce')
                    
                    current_date = pd.Timestamp.now()
                    tenure_days = (current_date - self.df[date_col]).dt.days
                    avg_tenure = tenure_days.mean() / 365.25
                    
                    if not np.isnan(avg_tenure):
                        kpis['avg_tenure'] = {
                            'value': f"{avg_tenure:.1f} Ø³Ù†ÙˆØ§Øª",
                            'label': 'Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¹Ù…Ø± Ø§Ù„ØªÙ†Ø¸ÙŠÙ…ÙŠ',
                            'icon': 'â³'
                        }
                except:
                    pass
        
        return kpis
    
    def _analyze_distributions(self):
        """ØªØ­Ù„ÙŠÙ„ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        distributions = {}
        
        # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…
        if 'department' in self.mapping:
            dept_col = self.mapping['department']
            if dept_col in self.df.columns:
                dept_dist = self.df[dept_col].value_counts().to_dict()
                distributions['department'] = dept_dist
        
        # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹
        if 'location' in self.mapping:
            loc_col = self.mapping['location']
            if loc_col in self.df.columns:
                loc_dist = self.df[loc_col].value_counts().to_dict()
                distributions['location'] = loc_dist
        
        # ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù
        if 'position' in self.mapping:
            pos_col = self.mapping['position']
            if pos_col in self.df.columns:
                pos_dist = self.df[pos_col].value_counts().head(10).to_dict()
                distributions['position'] = pos_dist
        
        # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§ØªØ¨
        if 'salary' in self.mapping:
            salary_col = self.mapping['salary']
            if salary_col in self.df.columns:
                try:
                    salary_data = pd.to_numeric(self.df[salary_col], errors='coerce').dropna()
                    if len(salary_data) > 0:
                        distributions['salary'] = {
                            'min': float(salary_data.min()),
                            'max': float(salary_data.max()),
                            'mean': float(salary_data.mean()),
                            'median': float(salary_data.median()),
                            'std': float(salary_data.std())
                        }
                except:
                    pass
        
        return distributions
    
    def _find_correlations(self):
        """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª"""
        correlations = {}
        
        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
        numeric_cols = []
        for field_type, col_name in self.mapping.items():
            if col_name in self.df.columns:
                try:
                    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø¹Ø¯Ø¯
                    numeric_series = pd.to_numeric(self.df[col_name], errors='coerce')
                    if numeric_series.notna().sum() > 0:  # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø£Ø±Ù‚Ø§Ù…
                        numeric_cols.append(col_name)
                        self.df[col_name] = numeric_series
                except:
                    continue
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø£ÙƒØ«Ø± Ù…Ù† Ø¹Ù…ÙˆØ¯ Ø±Ù‚Ù…ÙŠ
        if len(numeric_cols) >= 2:
            try:
                corr_matrix = self.df[numeric_cols].corr()
                correlations['matrix'] = corr_matrix.to_dict()
                
                # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ù‚ÙˆÙ‰ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª
                strong_correlations = []
                for i in range(len(corr_matrix.columns)):
                    for j in range(i+1, len(corr_matrix.columns)):
                        corr_value = corr_matrix.iloc[i, j]
                        if not pd.isna(corr_value) and abs(corr_value) > 0.5:
                            strong_correlations.append({
                                'col1': corr_matrix.columns[i],
                                'col2': corr_matrix.columns[j],
                                'correlation': corr_value
                            })
                
                correlations['strong'] = strong_correlations
            except:
                pass
        
        return correlations
    
    def _extract_insights(self):
        """Ø§Ø³ØªØ®Ù„Ø§Øµ Ø±Ø¤Ù‰ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        insights = []
        
        # 1. Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø£Ù‚Ø³Ø§Ù…
        if 'department' in self.mapping and 'salary' in self.mapping:
            dept_col = self.mapping['department']
            salary_col = self.mapping['salary']
            
            if dept_col in self.df.columns and salary_col in self.df.columns:
                try:
                    self.df[salary_col] = pd.to_numeric(self.df[salary_col], errors='coerce')
                    dept_salary = self.df.groupby(dept_col)[salary_col].mean().sort_values()
                    
                    if len(dept_salary) > 0:
                        highest_dept = dept_salary.idxmax()
                        lowest_dept = dept_salary.idxmin()
                        
                        insights.append(f"Ø£Ø¹Ù„Ù‰ Ø±Ø§ØªØ¨ ÙÙŠ Ù‚Ø³Ù…: **{highest_dept}**")
                        insights.append(f"Ø£Ù‚Ù„ Ø±Ø§ØªØ¨ ÙÙŠ Ù‚Ø³Ù…: **{lowest_dept}**")
                except:
                    pass
        
        # 2. Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø£Ø¯Ø§Ø¡ ÙˆØ±ÙˆØ§ØªØ¨
        if 'performance_score' in self.mapping and 'salary' in self.mapping:
            perf_col = self.mapping['performance_score']
            salary_col = self.mapping['salary']
            
            if perf_col in self.df.columns and salary_col in self.df.columns:
                try:
                    self.df[perf_col] = pd.to_numeric(self.df[perf_col], errors='coerce')
                    self.df[salary_col] = pd.to_numeric(self.df[salary_col], errors='coerce')
                    
                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… numpy
                    valid_data = self.df[[perf_col, salary_col]].dropna()
                    if len(valid_data) > 1:
                        correlation = np.corrcoef(valid_data[perf_col], valid_data[salary_col])[0, 1]
                        
                        if not np.isnan(correlation):
                            if correlation > 0.5:
                                insights.append("ğŸ“ˆ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø±Ø§ØªØ¨ **Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© ÙˆÙ‚ÙˆÙŠØ©**")
                            elif correlation > 0.3:
                                insights.append("ğŸ“ˆ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø±Ø§ØªØ¨ **Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©**")
                            elif correlation < -0.3:
                                insights.append("ğŸ“‰ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø±Ø§ØªØ¨ **Ø³Ù„Ø¨ÙŠØ©**")
                            else:
                                insights.append("âš–ï¸ **Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¹Ù„Ø§Ù‚Ø© ÙˆØ§Ø¶Ø­Ø©** Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø±Ø§ØªØ¨")
                except:
                    pass
        
        # 3. ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù†Ø³ (Ø¥Ø°Ø§ ÙˆØ¬Ø¯)
        gender_keywords = ['gender', 'sex', 'Ø¬Ù†Ø³', 'Ø§Ù„Ø¬Ù†Ø³']
        for col in self.df.columns:
            if any(keyword in str(col).lower() for keyword in gender_keywords):
                if self.df[col].nunique() <= 5:  # Ø¹Ù…ÙˆØ¯ ÙØ¦ÙˆÙŠ Ù…Ø­ØªÙ…Ù„
                    gender_dist = self.df[col].value_counts()
                    for gender, count in gender_dist.items():
                        percentage = (count / len(self.df)) * 100
                        insights.append(f"**{gender}**: {percentage:.1f}% Ù…Ù† Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†")
                    break
        
        return insights
    
    def _check_data_quality(self):
        """ÙØ­Øµ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - Ø¥ØµØ¯Ø§Ø± Ù…ØµØ­Ø­"""
        warnings = []
        
        # 1. ÙØ­Øµ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
        missing_percentage = (self.df.isnull().sum() / len(self.df)) * 100
        high_missing = missing_percentage[missing_percentage > 20].index.tolist()
        
        if high_missing:
            warnings.append(f"âš ï¸ Ø£Ø¹Ù…Ø¯Ø© Ø¨Ù‡Ø§ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø© >20%: {', '.join(high_missing[:5])}")
        
        # 2. ÙØ­Øµ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
        duplicates = self.df.duplicated().sum()
        if duplicates > 0:
            warnings.append(f"âš ï¸ ÙŠÙˆØ¬Ø¯ {duplicates} Ø³Ø¬Ù„ Ù…ÙƒØ±Ø±")
        
        # 3. ÙØ­Øµ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ·Ø±ÙØ© ÙÙŠ Ø§Ù„Ø±ÙˆØ§ØªØ¨ - Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
        if 'salary' in self.mapping:
            salary_col = self.mapping['salary']
            if salary_col in self.df.columns:
                try:
                    # Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø¹Ø¯Ø¯ ÙˆÙÙ„ØªØ±Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†Ø§Ù‚ØµØ©
                    salary_data = pd.to_numeric(self.df[salary_col], errors='coerce')
                    salary_data = salary_data.dropna()
                    
                    if len(salary_data) > 0:
                        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø±Ù‚Ù…ÙŠØ©
                        if pd.api.types.is_numeric_dtype(salary_data):
                            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ·Ø±ÙØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… IQR
                            q1 = salary_data.quantile(0.25)
                            q3 = salary_data.quantile(0.75)
                            iqr = q3 - q1
                            
                            if iqr > 0:  # ØªØ¬Ù†Ø¨ iqr = 0
                                lower_bound = q1 - 1.5 * iqr
                                upper_bound = q3 + 1.5 * iqr
                                
                                # Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ bound (Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… int)
                                outliers = salary_data[(salary_data < lower_bound) | (salary_data > upper_bound)]
                                
                                if len(outliers) > 0:
                                    warnings.append(f"âš ï¸ ØªÙ… Ø§ÙƒØªØ´Ø§Ù {len(outliers)} Ù‚ÙŠÙ…Ø© Ø´Ø§Ø°Ø© ÙÙŠ Ø§Ù„Ø±ÙˆØ§ØªØ¨ (Ø§Ø³ØªØ®Ø¯Ø§Ù… IQR)")
                        else:
                            warnings.append("âš ï¸ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø±Ø§ØªØ¨ Ù„ÙŠØ³ Ø¨ÙŠØ§Ù†Ø§Øª Ø±Ù‚Ù…ÙŠØ© (Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§ÙƒØªØ´Ø§Ù Ù‚ÙŠÙ… Ø´Ø§Ø°Ø©)")
                except Exception as e:
                    warnings.append(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©: {str(e)[:50]}")
        
        # 4. ÙØ­Øµ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® ØºÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©
        if 'hire_date' in self.mapping:
            date_col = self.mapping['hire_date']
            if date_col in self.df.columns:
                try:
                    dates = pd.to_datetime(self.df[date_col], errors='coerce')
                    future_dates = dates[dates > pd.Timestamp.now()]
                    if len(future_dates) > 0:
                        warnings.append(f"âš ï¸ ÙŠÙˆØ¬Ø¯ {len(future_dates)} ØªØ§Ø±ÙŠØ® ØªØ¹ÙŠÙŠÙ† ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„")
                except:
                    pass
        
        # 5. ØªØ­Ø°ÙŠØ± Ø¹Ø§Ù… Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ØªØ­Ù„ÙŠÙ„ ØºÙŠØ± Ù…ÙƒØªÙ…Ù„
        if len(self.df) < 10:
            warnings.append("âš ï¸ Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù‚Ù„ÙŠÙ„ Ø¬Ø¯Ø§Ù‹ØŒ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù‚Ø¯ Ù„Ø§ ØªÙƒÙˆÙ† Ø¯Ù‚ÙŠÙ‚Ø©")
        
        return warnings
    
    def get_modified_dataframe(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„"""
        return self.df
    
    def generate_report(self):
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ù†ØµÙŠ Ø¹Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ - Ø¥ØµØ¯Ø§Ø± Ù…Ø­Ø³Ù†"""
        try:
            report_lines = []
            
            # Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
            report_lines.append("=" * 80)
            report_lines.append("ØªÙ‚Ø±ÙŠØ± ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ©")
            report_lines.append("=" * 80)
            report_lines.append(f"ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙˆÙ„ÙŠØ¯: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
            report_lines.append("-" * 80)
            report_lines.append("")
            
            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ø§Ù…Ø©
            report_lines.append("ğŸ“‹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ø§Ù…Ø©:")
            report_lines.append(f"   â€¢ Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†: {len(self.df)}")
            report_lines.append(f"   â€¢ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {len(self.df.columns)}")
            
            # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
            used_columns = [v for v in self.mapping.values() if v not in ["âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯", "âŒ ØºÙŠØ± Ù…ØªÙˆÙØ±"]]
            if used_columns:
                report_lines.append(f"   â€¢ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©: {len(used_columns)} Ù…Ù† {len(self.df.columns)}")
            report_lines.append("")
            
            # KPIs
            kpis = self._calculate_kpis()
            report_lines.append("ğŸ“Š Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (KPIs):")
            for kpi_name, kpi_info in kpis.items():
                value = kpi_info['value']
                label = kpi_info['label']
                icon = kpi_info.get('icon', '')
                report_lines.append(f"   {icon} {label}: {value}")
            report_lines.append("")
            
            # Insights
            insights = self._extract_insights()
            if insights:
                report_lines.append("ğŸ’¡ Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ©:")
                for insight in insights:
                    report_lines.append(f"   â€¢ {insight}")
                report_lines.append("")
            
            # Warnings
            warnings = self._check_data_quality()
            if warnings:
                report_lines.append("âš ï¸ ØªØ­Ø°ÙŠØ±Ø§Øª Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
                for warning in warnings:
                    clean_warning = str(warning).replace('<', '').replace('>', '')
                    report_lines.append(f"   â€¢ {clean_warning}")
                report_lines.append("")
            
            # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…
            if 'department' in self.mapping:
                dept_col = self.mapping['department']
                if dept_col in self.df.columns:
                    dept_counts = self.df[dept_col].value_counts()
                    if len(dept_counts) > 0:
                        report_lines.append("ğŸ¢ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ† Ø­Ø³Ø¨ Ø§Ù„Ù‚Ø³Ù…:")
                        for dept, count in dept_counts.head(5).items():
                            percentage = (count / len(self.df)) * 100
                            report_lines.append(f"   â€¢ {dept}: {count} Ù…ÙˆØ¸Ù ({percentage:.1f}%)")
                        report_lines.append("")
            
            # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§ØªØ¨
            if 'salary' in self.mapping:
                salary_col = self.mapping['salary']
                if salary_col in self.df.columns:
                    salary_data = pd.to_numeric(self.df[salary_col], errors='coerce').dropna()
                    if len(salary_data) > 0:
                        report_lines.append("ğŸ’° Ù…Ù„Ø®Øµ Ø§Ù„Ø±ÙˆØ§ØªØ¨:")
                        report_lines.append(f"   â€¢ Ø£Ø¹Ù„Ù‰ Ø±Ø§ØªØ¨: ${salary_data.max():,.0f}")
                        report_lines.append(f"   â€¢ Ø£Ù‚Ù„ Ø±Ø§ØªØ¨: ${salary_data.min():,.0f}")
                        report_lines.append(f"   â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø±Ø§ØªØ¨: ${salary_data.mean():,.0f}")
                        report_lines.append(f"   â€¢ Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: ${salary_data.std():,.0f}")
                        report_lines.append("")
            
            # Recommendations
            report_lines.append("âœ… Ø§Ù„ØªÙˆØµÙŠØ§Øª:")
            report_lines.append("   1. Ù…Ø±Ø§Ø¬Ø¹Ø© Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø±ÙˆØ§ØªØ¨ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¹Ø¯Ø§Ù„Ø©")
            report_lines.append("   2. Ø±Ø¨Ø· Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ÙƒØ§ÙØ¢Øª Ø¨Ø§Ù„Ø£Ø¯Ø§Ø¡")
            report_lines.append("   3. ØªØ­Ù„ÙŠÙ„ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ù‡Ø¨ Ø¨ÙŠÙ† Ø§Ù„Ø£Ù‚Ø³Ø§Ù…")
            report_lines.append("   4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            report_lines.append("   5. ØªØ­Ø¯ÙŠØ« Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„ØªÙˆØ¸ÙŠÙ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
            report_lines.append("")
            
            # ØªØ°ÙŠÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
            report_lines.append("=" * 80)
            report_lines.append("Ù…Ù„Ø§Ø­Ø¸Ø§Øª:")
            report_lines.append("   â€¢ Ù‡Ø°Ø§ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¨ÙˆØ§Ø³Ø·Ø© Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… HR Ø§Ù„Ø°ÙƒÙŠØ©")
            report_lines.append("   â€¢ Ù„Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª: ÙØ±ÙŠÙ‚ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ©")
            report_lines.append("=" * 80)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
            report_text = "\n".join(report_lines)
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ±Ù…ÙŠØ² Ø§Ù„ØµØ­ÙŠØ­
            try:
                report_text = report_text.encode('utf-8').decode('utf-8')
            except:
                pass
            
            return report_text
            
        except Exception as e:
            error_report = f"""
============================================================
Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
============================================================
Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {str(e)}

Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:
- Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ: {len(self.df)}
- Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {len(self.df.columns)}
- Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¹ÙŠÙ†Ø©: {self.mapping}

ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.
============================================================
"""
            return error_report